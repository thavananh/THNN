{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8502378,"sourceType":"datasetVersion","datasetId":5074342},{"sourceId":11710070,"sourceType":"datasetVersion","datasetId":7350237},{"sourceId":11711397,"sourceType":"datasetVersion","datasetId":7351383},{"sourceId":11711551,"sourceType":"datasetVersion","datasetId":7351466},{"sourceId":11716446,"sourceType":"datasetVersion","datasetId":7354572},{"sourceId":11716604,"sourceType":"datasetVersion","datasetId":7354691},{"sourceId":374509,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":309621,"modelId":329993}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install \"modin[all]\" \n!pip install swifter\n!pip install swifter[notebook]\n!pip install swifter[groupby]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import modin.pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Đọc dữ liệu\n# df = pd.read_csv(\"/kaggle/input/phishing-email-dataset/phishing_email.csv\")\ndf = pd.read_excel(\"/kaggle/input/phishing-email-vietnamese-v2-excel/phishing_email_with_translation_clean_small.xlsx\")\ndf.info()\n\ndf['length'] = df['translation'].apply(lambda x: len(x.split()))\n\nsns.set_style(\"whitegrid\")\n\nplt.figure(figsize=(8, 6))\nplt.pie(df['label'].value_counts(), labels=['ham (not spam)', 'spam'], autopct='%1.1f%%')\nplt.title('Tỷ lệ các loại Email', fontsize=14)\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(8, 6))\nsns.violinplot(x='label', y='length', data=df, palette='viridis')\nplt.title('Phân bố số lượng từ trong Email theo nhãn', fontsize=14)\nplt.xlabel('Nhãn', fontsize=12)\nplt.ylabel('Số lượng từ trong Email', fontsize=12)\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(8, 6))\nax = sns.countplot(x='label', data=df, palette='viridis')\nfor container in ax.containers:\n    ax.bar_label(container)\nplt.title('Phân bố các loại Email', fontsize=14)\nplt.xlabel('Nhãn', fontsize=12)\nplt.ylabel('Số lượng Email', fontsize=12)\nplt.xticks(ticks=[0, 1], labels=['ham (not spam)', 'spam'])\nplt.tight_layout()\nplt.show()\n\n# Lưu các biểu đồ\nplt.figure(figsize=(8, 6))\nplt.pie(df['label'].value_counts(), labels=['ham (not spam)', 'spam'], autopct='%1.1f%%')\nplt.title('Tỷ lệ các loại Email', fontsize=14)\nplt.tight_layout()\nplt.savefig('email_piechart.png')\nplt.close()\n\nplt.figure(figsize=(8, 6))\nsns.violinplot(x='label', y='length', data=df, palette='viridis')\nplt.title('Phân bố số lượng từ trong Email theo nhãn', fontsize=14)\nplt.xlabel('Nhãn', fontsize=12)\nplt.ylabel('Số lượng từ trong Email', fontsize=12)\nplt.tight_layout()\nplt.savefig('email_length_distribution.png')\nplt.close()\n\nplt.figure(figsize=(8, 6))\nax = sns.countplot(x='label', data=df, palette='viridis')\nfor container in ax.containers:\n    ax.bar_label(container)\nplt.title('Phân bố các loại Email', fontsize=14)\nplt.xlabel('Nhãn', fontsize=12)\nplt.ylabel('Số lượng Email', fontsize=12)\nplt.xticks(ticks=[0, 1], labels=['ham (not spam)', 'spam'])\nplt.tight_layout()\nplt.savefig('email_distribution.png')\nplt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport re\nimport unicodedata\nimport gc\nimport json\nimport random\nimport joblib\n\nfrom joblib import Parallel, delayed\nfrom collections import Counter\n\nimport modin.pandas as pd\nimport swifter\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nimport numpy as np\nfrom gensim.models import Word2Vec, KeyedVectors\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\n\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nEMBEDDING_DIM     = 200\nHIDDEN_DIM        = 128\nNUM_HEADS         = 4\nNUM_FILTERS       = 200\nKERNEL_SIZES      = [2]\nDROPOUT           = 0.2\nLR                = 1e-3\nBATCH_SIZE        = 16\nNUM_EPOCHS        = 30\nMAX_LEN           = 256\nPAD_TOKEN         = \"<pad>\"\nUNK_TOKEN         = \"<unk>\"\nTEST_SPLIT_RATIO  = 0.2\nFREEZE_EMBEDDINGS = False\nPATIENCE          = 5\n\nBEST_MODEL_FILENAME = 'best_email_classifier.pt'\nARTIFACTS_DIR       = 'artifacts'\nos.makedirs(ARTIFACTS_DIR, exist_ok=True)\n\nW2V_WINDOW    = 15\nW2V_MIN_COUNT = 10\nW2V_WORKERS   = os.cpu_count()\nW2V_RUNS      = 1\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\nnltk.download('wordnet', quiet=True)\nnltk.download('stopwords', quiet=True)\nnltk.download('punkt', quiet=True)\n\ndef normalize_text(text):\n    if not isinstance(text, str):\n        return \"\"\n    text = unicodedata.normalize('NFKC', text).lower()\n    text = re.sub(r'[^a-z\\s]', ' ', text)\n    return re.sub(r'\\s+', ' ', text).strip()\n\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words('english')).union({\n    'subject','re','fw','fwd','sent','from','to','cc','bcc',\n    'http','https','www','com','org','net','am','pm',\n    'dear','hello','hi','thanks','best','regards',\n    'please','mail','email','message','list','address','nbsp'\n})\n\ndef preprocess_data(filepath, max_len):\n    print(\"Start preprocessing data...\")\n    df = pd.read_csv(filepath)\n    df = df.dropna(subset=['text_combined']).reset_index(drop=True)\n    gc.collect()\n\n    def tokenize_and_lemmatize(text):\n        toks = word_tokenize(text)\n        return toks\n\n    print(df['text_combined'])\n    texts = df['text_combined'].tolist()\n    sentences = Parallel(n_jobs=W2V_WORKERS, backend=\"threading\")(  \n        delayed(tokenize_and_lemmatize)(text) for text in tqdm(texts, desc=\"Tokenizing texts\", total=len(texts))\n    )\n    toks_for_w2v = sentences\n    raw_labels = df['label'].astype(str).str.strip().tolist()\n    print(\"Preprocessing completed.\")\n\n    all_words = Counter([w for sent in toks_for_w2v for w in sent])\n    vocab = {w: i+2 for i, w in enumerate(all_words.keys())}\n    vocab[PAD_TOKEN] = 0\n    vocab[UNK_TOKEN] = 1\n    unique_labels = sorted(set(raw_labels))\n    label_map    = {lbl: i for i, lbl in enumerate(unique_labels)}\n    idx_to_label = {i: lbl for lbl, i in label_map.items()}\n\n    X, Y = [], []\n    for toks, lbl in zip(sentences, raw_labels):\n        nums = [vocab.get(t, vocab[UNK_TOKEN]) for t in toks]\n        if len(nums) < max_len:\n            nums += [vocab[PAD_TOKEN]] * (max_len - len(nums))\n        else:\n            nums = nums[:max_len]\n        X.append(nums)\n        Y.append(label_map[lbl])\n    return X, Y, toks_for_w2v, vocab, label_map, idx_to_label\n\ndef train_word2vec_avg(tokenized_sentences, embedding_dim, window, min_count, runs=1):\n    print(\"\\nStart Word2Vec training...\")\n    tokenized_sentences = list(tokenized_sentences)\n    sum_vec, keys = None, None\n    cpu_cores = os.cpu_count()\n    for _ in tqdm(range(runs), desc=\"Word2Vec runs\"):\n        model = Word2Vec(\n            sentences=tokenized_sentences,\n            vector_size=embedding_dim,\n            window=window,\n            min_count=min_count,\n            workers=cpu_cores,\n            sg=1,\n            epochs=5,\n            batch_words=10000\n        )\n        vecs = model.wv.vectors\n        if sum_vec is None:\n            sum_vec = vecs.astype(np.float32)\n            keys = model.wv.index_to_key\n        else:\n            sum_vec += vecs\n    avg_vec = sum_vec / runs\n    kv = KeyedVectors(vector_size=embedding_dim)\n    kv.add_vectors(keys, avg_vec)\n    print(\"Word2Vec training completed.\")\n    return kv\n\ndef create_embedding_matrix(kv, vocab, embedding_dim):\n    print(\"Creating embedding matrix...\")\n    mat = np.zeros((len(vocab), embedding_dim))\n    cnt = 0\n    for w, idx in vocab.items():\n        if w in kv:\n            mat[idx] = kv[w]\n            cnt += 1\n    print(f\"Initialized {cnt}/{len(vocab)} tokens.\")\n    return torch.tensor(mat, dtype=torch.float)\n\nclass SentimentDataset(Dataset):\n    def __init__(self, X, Y):\n        self.X = X\n        self.Y = Y\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        return torch.tensor(self.X[idx], dtype=torch.long), torch.tensor(self.Y[idx], dtype=torch.long)\n\nclass CNNBiLSTM_MHA(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, num_filters, kernel_sizes,\n                 hidden_dim, num_heads, output_dim, dropout, pad_idx,\n                 pretrained_matrix=None, freeze_embeddings=False):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n        if pretrained_matrix is not None:\n            print(\"Loading pretrained embeddings...\")\n            self.embedding.weight.data.copy_(pretrained_matrix)\n            self.embedding.weight.requires_grad = not freeze_embeddings\n        else:\n            print(\"Training embeddings from scratch.\")\n        self.convs = nn.ModuleList([nn.Conv1d(embedding_dim, num_filters, ks) for ks in kernel_sizes])\n        self.lstm  = nn.LSTM(num_filters, hidden_dim, batch_first=True, bidirectional=True)\n        self.attn  = nn.MultiheadAttention(embed_dim=hidden_dim*2, num_heads=num_heads, dropout=dropout, batch_first=True)\n        self.dropout = nn.Dropout(dropout)\n        self.fc      = nn.Linear(hidden_dim*2, output_dim)\n        self.pad_idx = pad_idx\n\n    def forward(self, text):\n        mask = (text == self.pad_idx)\n        emb  = self.dropout(self.embedding(text))\n        x    = emb.permute(0, 2, 1)\n        c    = torch.relu(self.convs[0](x)).permute(0,2,1)\n        out, _ = self.lstm(self.dropout(c))\n        if out.size(1) != mask.size(1):\n            diff = out.size(1) - mask.size(1)\n            if diff > 0:\n                mask = torch.cat([mask, mask.new_ones(mask.size(0), diff)], dim=1)\n            else:\n                mask = mask[:, :out.size(1)]\n        attn_out, _ = self.attn(out, out, out, key_padding_mask=mask)\n        attn_out    = attn_out.masked_fill(mask.unsqueeze(-1), 0.0)\n        summed      = attn_out.sum(1)\n        cnt_nonpad  = (~mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled      = summed / cnt_nonpad\n        return self.fc(self.dropout(pooled))\n\ndef train_model(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    all_preds, all_labels = [], []\n    for Xb, yb in tqdm(loader, desc=\"Training batches\"):\n        Xb, yb = Xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        logits = model(Xb)\n        loss   = criterion(logits, yb)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        preds = logits.argmax(dim=1).detach().cpu().numpy()\n        all_preds.append(preds)\n        all_labels.append(yb.cpu().numpy())\n    avg_loss = total_loss / len(loader)\n    y_pred   = np.concatenate(all_preds)\n    y_true   = np.concatenate(all_labels)\n    acc      = accuracy_score(y_true, y_pred)\n    f1       = f1_score(y_true, y_pred, average='macro', zero_division=0)\n    return avg_loss, acc, f1\n\ndef evaluate_model(model, loader, criterion, idx_to_label):\n    model.eval()\n    total_loss = 0\n    all_preds, all_labels = [], []\n    for Xb, yb in tqdm(loader, desc=\"Evaluation batches\"):\n        with torch.no_grad():\n            Xb, yb = Xb.to(device), yb.to(device)\n            logits = model(Xb)\n            total_loss += criterion(logits, yb).item()\n            preds = logits.argmax(dim=1).cpu().numpy()\n            all_preds.append(preds)\n            all_labels.append(yb.cpu().numpy())\n    avg_loss = total_loss / len(loader)\n    y_pred   = np.concatenate(all_preds)\n    y_true   = np.concatenate(all_labels)\n    acc      = accuracy_score(y_true, y_pred)\n    f1       = f1_score(y_true, y_pred, average='macro', zero_division=0)\n    print(\"\\n--- Classification Report ---\")\n    print(classification_report(\n        y_true, y_pred,\n        target_names=[idx_to_label[i] for i in range(len(idx_to_label))],\n        zero_division=0, digits=4\n    ))\n    # print(confusion_matrix(y_true, y_pred))\n    return avg_loss, acc, f1\n\ndef save_data_artifacts(vocab, label_map, idx_to_label, cv, tv, emb_mat, X, Y, kv, artifacts_dir=ARTIFACTS_DIR):\n    os.makedirs(artifacts_dir, exist_ok=True)\n    print(\"Saving data artifacts...\")\n    joblib.dump(vocab, os.path.join(artifacts_dir, 'vocab.joblib'))\n    joblib.dump(label_map, os.path.join(artifacts_dir, 'label_map.joblib'))\n    joblib.dump(idx_to_label, os.path.join(artifacts_dir, 'idx_to_label.joblib'))\n    joblib.dump(cv, os.path.join(artifacts_dir, 'count_vectorizer.joblib'))\n    joblib.dump(tv, os.path.join(artifacts_dir, 'tfidf_vectorizer.joblib'))\n    joblib.dump(emb_mat, os.path.join(artifacts_dir, 'embedding_matrix.joblib'))\n    joblib.dump((X, Y), os.path.join(artifacts_dir, 'dataset_XY.joblib'))\n    kv.save(os.path.join(artifacts_dir, 'word2vec_avg.kv'))\n    print(f\"✅ Data artifacts saved to {artifacts_dir}/\")\n\ndef load_data_artifacts(artifacts_dir=ARTIFACTS_DIR):\n    print(\"Loading data artifacts...\")\n    vocab        = joblib.load(os.path.join(artifacts_dir, 'vocab.joblib'))\n    label_map    = joblib.load(os.path.join(artifacts_dir, 'label_map.joblib'))\n    idx_to_label = joblib.load(os.path.join(artifacts_dir, 'idx_to_label.joblib'))\n    cv           = joblib.load(os.path.join(artifacts_dir, 'count_vectorizer.joblib'))\n    tv           = joblib.load(os.path.join(artifacts_dir, 'tfidf_vectorizer.joblib'))\n    emb_mat      = joblib.load(os.path.join(artifacts_dir, 'embedding_matrix.joblib'))\n    X, Y         = joblib.load(os.path.join(artifacts_dir, 'dataset_XY.joblib'))\n    kv           = KeyedVectors.load(os.path.join(artifacts_dir, 'word2vec_avg.kv'), mmap='r')\n    print(f\"✅ Data artifacts loaded from {artifacts_dir}/\")\n    return X, Y, vocab, label_map, idx_to_label, cv, tv, emb_mat, kv\n\ndata_file = os.path.join(ARTIFACTS_DIR, 'dataset_XY.joblib')\nif os.path.exists(data_file):\n    X, Y, vocab, label_map, idx_to_label, cv, tv, emb_mat, kv = load_data_artifacts()\nelse:\n    X, Y, toks, vocab, label_map, idx_to_label, cv, tv = preprocess_data(\n        \"/kaggle/input/phishing-email-dataset/phishing_email.csv\", MAX_LEN\n    )\n    kv      = train_word2vec_avg(toks, EMBEDDING_DIM, W2V_WINDOW, W2V_MIN_COUNT, runs=2)\n    emb_mat = create_embedding_matrix(kv, vocab, EMBEDDING_DIM)\n    save_data_artifacts(vocab, label_map, idx_to_label, cv, tv, emb_mat, X, Y, kv)\n\nprint(\"Preparing data loaders...\")\ndataset   = SentimentDataset(X, Y)\ntest_size = int(len(dataset) * TEST_SPLIT_RATIO)\ntrain_size= len(dataset) - test_size\ntrain_ds, test_ds = (\n    random_split(dataset, [train_size, test_size]) if test_size>0 else (dataset, None)\n)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE) if test_ds else None\n\nprint(emb_mat)\nmodel = CNNBiLSTM_MHA(\n    vocab_size=len(vocab), embedding_dim=EMBEDDING_DIM,\n    num_filters=NUM_FILTERS, kernel_sizes=KERNEL_SIZES,\n    hidden_dim=HIDDEN_DIM, num_heads=NUM_HEADS,\n    output_dim=len(label_map), dropout=DROPOUT,\n    pad_idx=vocab[PAD_TOKEN], pretrained_matrix=emb_mat,\n    freeze_embeddings=FREEZE_EMBEDDINGS\n).to(device)\noptimizer = optim.Adam(model.parameters(), lr=LR)\ncriterion = nn.CrossEntropyLoss()\n\nbest_f1 = 0.0\nepochs_no_improve = 0\nprint(\"Starting training...\")\nfor epoch in tqdm(range(NUM_EPOCHS), desc=\"Epochs\"):\n    tr_loss, tr_acc, tr_f1 = train_model(model, train_loader, optimizer, criterion)\n    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} — loss: {tr_loss:.4f} — acc: {tr_acc:.4f} — f1: {tr_f1:.4f}\")\n    if test_loader:\n        val_loss, val_acc, val_f1 = evaluate_model(model, test_loader, criterion, idx_to_label)\n        print(f\"Validation — loss: {val_loss:.4f} — acc: {val_acc:.4f} — f1: {val_f1:.4f}\\n\")\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            epochs_no_improve = 0\n            torch.save(model.state_dict(), os.path.join(ARTIFACTS_DIR, BEST_MODEL_FILENAME))\n            print(f\"✅ Model state saved to {BEST_MODEL_FILENAME}\")\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= PATIENCE:\n                print(f\"Early stopping at epoch {epoch+1}.\")\n                break\n\nif test_loader:\n    all_preds = []\n    all_labels = []\n    model.eval()\n    with torch.no_grad():\n        for texts, labels in test_loader:\n            logits = model(texts.to(device))\n            preds = logits.argmax(dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n\n    conf_matrix = confusion_matrix(all_labels, all_preds)\n    print(classification_report(all_labels, all_preds, digits=4))\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n                 xticklabels=list(label_map.keys()), yticklabels=list(label_map.keys()))\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\nsample = \"Congratulations! You've won a free ticket. Click here...\"\ntoks   = sample.lower().split()\nnums   = [vocab.get(t, vocab[UNK_TOKEN]) for t in toks]\nnums   = nums[:MAX_LEN] + [vocab[PAD_TOKEN]]*(MAX_LEN-len(nums))\nmodel.eval()\nwith torch.no_grad():\n    logits = model(torch.tensor([nums], dtype=torch.long).to(device))\n    pred   = logits.argmax(dim=1).item()\nprint(f\"Sample prediction: {idx_to_label[pred]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install \"modin[all]\" \n!pip install swifter\n!pip install swifter[notebook]\n!pip install swifter[groupby]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport re\nimport unicodedata\nimport gc\nimport json\nimport random\nimport joblib\n\nfrom joblib import Parallel, delayed\nfrom collections import Counter\n\nimport modin.pandas as pd\nimport swifter\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nimport numpy as np\nfrom gensim.models import Word2Vec, KeyedVectors\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\n\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nEMBEDDING_DIM     = 200\nHIDDEN_DIM        = 128\nNUM_HEADS         = 4\nNUM_FILTERS       = 200\nKERNEL_SIZES      = [2]\nDROPOUT           = 0.2\nLR                = 1e-4\nBATCH_SIZE        = 8\nNUM_EPOCHS        = 30\nMAX_LEN           = 256\nPAD_TOKEN         = \"<pad>\"\nUNK_TOKEN         = \"<unk>\"\nTEST_SPLIT_RATIO  = 0.2\nFREEZE_EMBEDDINGS = False\nPATIENCE          = 5\n\nBEST_MODEL_FILENAME = 'best_email_classifier.pt'\nARTIFACTS_DIR       = 'artifacts_lstm_cnn_bilingual'\nos.makedirs(ARTIFACTS_DIR, exist_ok=True)\n\nW2V_WINDOW    = 15\nW2V_MIN_COUNT = 10\nW2V_WORKERS   = os.cpu_count()\nW2V_RUNS      = 1\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\nnltk.download('wordnet', quiet=True)\nnltk.download('stopwords', quiet=True)\nnltk.download('punkt', quiet=True)\n\ndef normalize_text(text):\n    if not isinstance(text, str):\n        return \"\"\n    text = unicodedata.normalize('NFKC', text).lower()\n    text = re.sub(r'[^a-z\\s]', ' ', text)\n    return re.sub(r'\\s+', ' ', text).strip()\n\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words('english')).union({\n    'subject','re','fw','fwd','sent','from','to','cc','bcc',\n    'http','https','www','com','org','net','am','pm',\n    'dear','hello','hi','thanks','best','regards',\n    'please','mail','email','message','list','address','nbsp'\n})\n\ndef preprocess_data(filepath, max_len):\n    print(\"Start preprocessing data...\")\n    df = pd.read_excel(filepath)\n    df = df.dropna(subset=['translation']).reset_index(drop=True)\n    gc.collect()\n\n    def tokenize_and_lemmatize(text):\n        toks = word_tokenize(text)\n        return toks\n\n    print(df['translation'])\n    texts = df['translation'].tolist()\n    sentences = Parallel(n_jobs=W2V_WORKERS, backend=\"threading\")(  \n        delayed(tokenize_and_lemmatize)(text) for text in tqdm(texts, desc=\"Tokenizing texts\", total=len(texts))\n    )\n    toks_for_w2v = sentences\n    raw_labels = df['label'].astype(str).str.strip().tolist()\n    print(\"Preprocessing completed.\")\n\n    all_words = Counter([w for sent in toks_for_w2v for w in sent])\n    vocab = {w: i+2 for i, w in enumerate(all_words.keys())}\n    vocab[PAD_TOKEN] = 0\n    vocab[UNK_TOKEN] = 1\n    unique_labels = sorted(set(raw_labels))\n    label_map    = {lbl: i for i, lbl in enumerate(unique_labels)}\n    idx_to_label = {i: lbl for lbl, i in label_map.items()}\n\n    X, Y = [], []\n    for toks, lbl in zip(sentences, raw_labels):\n        nums = [vocab.get(t, vocab[UNK_TOKEN]) for t in toks]\n        if len(nums) < max_len:\n            nums += [vocab[PAD_TOKEN]] * (max_len - len(nums))\n        else:\n            nums = nums[:max_len]\n        X.append(nums)\n        Y.append(label_map[lbl])\n    return X, Y, toks_for_w2v, vocab, label_map, idx_to_label\n\ndef train_word2vec_avg(tokenized_sentences, embedding_dim, window, min_count, runs=1):\n    print(\"\\nStart Word2Vec training...\")\n    tokenized_sentences = list(tokenized_sentences)\n    sum_vec, keys = None, None\n    cpu_cores = os.cpu_count()\n    for _ in tqdm(range(runs), desc=\"Word2Vec runs\"):\n        model = Word2Vec(\n            sentences=tokenized_sentences,\n            vector_size=embedding_dim,\n            window=window,\n            min_count=min_count,\n            workers=cpu_cores,\n            sg=1,\n            epochs=5,\n            batch_words=10000\n        )\n        vecs = model.wv.vectors\n        if sum_vec is None:\n            sum_vec = vecs.astype(np.float32)\n            keys = model.wv.index_to_key\n        else:\n            sum_vec += vecs\n    avg_vec = sum_vec / runs\n    kv = KeyedVectors(vector_size=embedding_dim)\n    kv.add_vectors(keys, avg_vec)\n    print(\"Word2Vec training completed.\")\n    return kv\n\ndef create_embedding_matrix(kv, vocab, embedding_dim):\n    print(\"Creating embedding matrix...\")\n    mat = np.zeros((len(vocab), embedding_dim))\n    cnt = 0\n    for w, idx in vocab.items():\n        if w in kv:\n            mat[idx] = kv[w]\n            cnt += 1\n    print(f\"Initialized {cnt}/{len(vocab)} tokens.\")\n    return torch.tensor(mat, dtype=torch.float)\n\nclass SentimentDataset(Dataset):\n    def __init__(self, X, Y):\n        self.X = X\n        self.Y = Y\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        return torch.tensor(self.X[idx], dtype=torch.long), torch.tensor(self.Y[idx], dtype=torch.long)\n\nclass CNNBiLSTM_MHA(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, num_filters, kernel_sizes,\n                 hidden_dim, num_heads, output_dim, dropout, pad_idx,\n                 pretrained_matrix=None, freeze_embeddings=False):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n        if pretrained_matrix is not None:\n            print(\"Loading pretrained embeddings...\")\n            self.embedding.weight.data.copy_(pretrained_matrix)\n            self.embedding.weight.requires_grad = not freeze_embeddings\n        else:\n            print(\"Training embeddings from scratch.\")\n        self.convs = nn.ModuleList([nn.Conv1d(embedding_dim, num_filters, ks) for ks in kernel_sizes])\n        self.lstm  = nn.LSTM(num_filters, hidden_dim, batch_first=True, bidirectional=True)\n        self.attn  = nn.MultiheadAttention(embed_dim=hidden_dim*2, num_heads=num_heads, dropout=dropout, batch_first=True)\n        self.dropout = nn.Dropout(dropout)\n        self.fc      = nn.Linear(hidden_dim*2, output_dim)\n        self.pad_idx = pad_idx\n\n    def forward(self, text):\n        mask = (text == self.pad_idx)\n        emb  = self.dropout(self.embedding(text))\n        x    = emb.permute(0, 2, 1)\n        c    = torch.relu(self.convs[0](x)).permute(0,2,1)\n        out, _ = self.lstm(self.dropout(c))\n        if out.size(1) != mask.size(1):\n            diff = out.size(1) - mask.size(1)\n            if diff > 0:\n                mask = torch.cat([mask, mask.new_ones(mask.size(0), diff)], dim=1)\n            else:\n                mask = mask[:, :out.size(1)]\n        attn_out, _ = self.attn(out, out, out, key_padding_mask=mask)\n        attn_out    = attn_out.masked_fill(mask.unsqueeze(-1), 0.0)\n        summed      = attn_out.sum(1)\n        cnt_nonpad  = (~mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled      = summed / cnt_nonpad\n        return self.fc(self.dropout(pooled))\n\ndef train_model(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    all_preds, all_labels = [], []\n    for Xb, yb in tqdm(loader, desc=\"Training batches\"):\n        Xb, yb = Xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        logits = model(Xb)\n        loss   = criterion(logits, yb)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        preds = logits.argmax(dim=1).detach().cpu().numpy()\n        all_preds.append(preds)\n        all_labels.append(yb.cpu().numpy())\n    avg_loss = total_loss / len(loader)\n    y_pred   = np.concatenate(all_preds)\n    y_true   = np.concatenate(all_labels)\n    acc      = accuracy_score(y_true, y_pred)\n    f1       = f1_score(y_true, y_pred, average='macro', zero_division=0)\n    return avg_loss, acc, f1\n\ndef evaluate_model(model, loader, criterion, idx_to_label):\n    model.eval()\n    total_loss = 0\n    all_preds, all_labels = [], []\n    for Xb, yb in tqdm(loader, desc=\"Evaluation batches\"):\n        with torch.no_grad():\n            Xb, yb = Xb.to(device), yb.to(device)\n            logits = model(Xb)\n            total_loss += criterion(logits, yb).item()\n            preds = logits.argmax(dim=1).cpu().numpy()\n            all_preds.append(preds)\n            all_labels.append(yb.cpu().numpy())\n    avg_loss = total_loss / len(loader)\n    y_pred   = np.concatenate(all_preds)\n    y_true   = np.concatenate(all_labels)\n    acc      = accuracy_score(y_true, y_pred)\n    f1       = f1_score(y_true, y_pred, average='macro', zero_division=0)\n    print(\"\\n--- Classification Report ---\")\n    print(classification_report(\n        y_true, y_pred,\n        target_names=[idx_to_label[i] for i in range(len(idx_to_label))],\n        zero_division=0, digits=4\n    ))\n    # print(confusion_matrix(y_true, y_pred))\n    return avg_loss, acc, f1\n\ndef save_data_artifacts(vocab, label_map, idx_to_label, emb_mat, X, Y, kv, artifacts_dir=ARTIFACTS_DIR):\n    os.makedirs(artifacts_dir, exist_ok=True)\n    print(\"Saving data artifacts...\")\n    joblib.dump(vocab, os.path.join(artifacts_dir, 'vocab.joblib'))\n    joblib.dump(label_map, os.path.join(artifacts_dir, 'label_map.joblib'))\n    joblib.dump(idx_to_label, os.path.join(artifacts_dir, 'idx_to_label.joblib'))\n    # joblib.dump(cv, os.path.join(artifacts_dir, 'count_vectorizer.joblib'))\n    # joblib.dump(tv, os.path.join(artifacts_dir, 'tfidf_vectorizer.joblib'))\n    joblib.dump(emb_mat, os.path.join(artifacts_dir, 'embedding_matrix.joblib'))\n    joblib.dump((X, Y), os.path.join(artifacts_dir, 'dataset_XY.joblib'))\n    kv.save(os.path.join(artifacts_dir, 'word2vec_avg.kv'))\n    print(f\"✅ Data artifacts saved to {artifacts_dir}/\")\n\ndef load_data_artifacts(artifacts_dir=ARTIFACTS_DIR):\n    print(\"Loading data artifacts...\")\n    vocab        = joblib.load(os.path.join(artifacts_dir, 'vocab.joblib'))\n    label_map    = joblib.load(os.path.join(artifacts_dir, 'label_map.joblib'))\n    idx_to_label = joblib.load(os.path.join(artifacts_dir, 'idx_to_label.joblib'))\n    # cv           = joblib.load(os.path.join(artifacts_dir, 'count_vectorizer.joblib'))\n    # tv           = joblib.load(os.path.join(artifacts_dir, 'tfidf_vectorizer.joblib'))\n    emb_mat      = joblib.load(os.path.join(artifacts_dir, 'embedding_matrix.joblib'))\n    X, Y         = joblib.load(os.path.join(artifacts_dir, 'dataset_XY.joblib'))\n    kv           = KeyedVectors.load(os.path.join(artifacts_dir, 'word2vec_avg.kv'), mmap='r')\n    print(f\"✅ Data artifacts loaded from {artifacts_dir}/\")\n    return X, Y, vocab, label_map, idx_to_label, emb_mat, kv\n\ndata_file = os.path.join(ARTIFACTS_DIR, 'dataset_XY.joblib')\nif os.path.exists(data_file):\n    X, Y, vocab, label_map, idx_to_label, emb_mat, kv = load_data_artifacts()\nelse:\n    X, Y, toks, vocab, label_map, idx_to_label, = preprocess_data(\n        \"/kaggle/input/phishing-email-vietnamese-v2-excel/phishing_email_with_translation_clean_small.xlsx\", MAX_LEN\n    )\n    kv      = train_word2vec_avg(toks, EMBEDDING_DIM, W2V_WINDOW, W2V_MIN_COUNT, runs=2)\n    emb_mat = create_embedding_matrix(kv, vocab, EMBEDDING_DIM)\n    save_data_artifacts(vocab, label_map, idx_to_label, emb_mat, X, Y, kv)\n\nprint(\"Preparing data loaders...\")\ndataset   = SentimentDataset(X, Y)\ntest_size = int(len(dataset) * TEST_SPLIT_RATIO)\ntrain_size= len(dataset) - test_size\ntrain_ds, test_ds = (\n    random_split(dataset, [train_size, test_size]) if test_size>0 else (dataset, None)\n)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE) if test_ds else None\n\nprint(emb_mat)\nmodel = CNNBiLSTM_MHA(\n    vocab_size=len(vocab), embedding_dim=EMBEDDING_DIM,\n    num_filters=NUM_FILTERS, kernel_sizes=KERNEL_SIZES,\n    hidden_dim=HIDDEN_DIM, num_heads=NUM_HEADS,\n    output_dim=len(label_map), dropout=DROPOUT,\n    pad_idx=vocab[PAD_TOKEN], pretrained_matrix=emb_mat,# Final classification report and confusion matrix\n    \nprint(\"\\n--- Final Evaluation on Test Set ---\")\nprint(classification_report(all_labels, all_preds, target_names=label_map.keys(), digits=4))\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()\n    freeze_embeddings=FREEZE_EMBEDDINGS\n).to(device)\noptimizer = optim.Adam(model.parameters(), lr=LR)\ncriterion = nn.CrossEntropyLoss()\n\nbest_f1 = 0.0\nepochs_no_improve = 0\nprint(\"Starting training...\")\nfor epoch in tqdm(range(NUM_EPOCHS), desc=\"Epochs\"):\n    tr_loss, tr_acc, tr_f1 = train_model(model, train_loader, optimizer, criterion)\n    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} — loss: {tr_loss:.4f} — acc: {tr_acc:.4f} — f1: {tr_f1:.4f}\")\n    if test_loader:\n        val_loss, val_acc, val_f1 = evaluate_model(model, test_loader, criterion, idx_to_label)\n        print(f\"Validation — loss: {val_loss:.4f} — acc: {val_acc:.4f} — f1: {val_f1:.4f}\\n\")\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            epochs_no_improve = 0\n            torch.save(model.state_dict(), os.path.join(ARTIFACTS_DIR, BEST_MODEL_FILENAME))\n            print(f\"✅ Model state saved to {BEST_MODEL_FILENAME}\")\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= PATIENCE:\n                print(f\"Early stopping at epoch {epoch+1}.\")\n                break\n\nif test_loader:\n    all_preds = []\n    all_labels = []\n    model.eval()\n    with torch.no_grad():\n        for texts, labels in test_loader:\n            logits = model(texts.to(device))\n            preds = logits.argmax(dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n\n    conf_matrix = confusion_matrix(all_labels, all_preds)\n    print(classification_report(all_labels, all_preds, digits=4))\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n                 xticklabels=list(label_map.keys()), yticklabels=list(label_map.keys()))\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\nsample = \"Congratulations! You've won a free ticket. Click here...\"\ntoks   = sample.lower().split()\nnums   = [vocab.get(t, vocab[UNK_TOKEN]) for t in toks]\nnums   = nums[:MAX_LEN] + [vocab[PAD_TOKEN]]*(MAX_LEN-len(nums))\nmodel.eval()\nwith torch.no_grad():\n    logits = model(torch.tensor([nums], dtype=torch.long).to(device))\n    pred   = logits.argmax(dim=1).item()\nprint(f\"Sample prediction: {idx_to_label[pred]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport gc\nimport json\nimport random\n\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nfrom torch.optim import AdamW\n\n# ==================== Configuration ====================\nMODEL_NAME        = 'vinai/phobert-base-v2'   # or your preferred BERT model\nMAX_LEN           = 256\nBATCH_SIZE        = 16\nNUM_EPOCHS        = 5\nLR                = 2e-5\nWARMUP_STEPS      = 0\nWEIGHT_DECAY      = 0.01\nTEST_SPLIT_RATIO  = 0.2\nPATIENCE          = 3\nFREEZE_BERT       = False\nDEVICE            = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nARTIFACTS_DIR     = 'artifacts_albert'\nos.makedirs(ARTIFACTS_DIR, exist_ok=True)\n\n# Initialize tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\nclass EmailDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts    = texts\n        self.labels   = labels\n        self.tokenizer= tokenizer\n        self.max_len  = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label= self.labels[idx]\n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        item = {\n            'input_ids':      encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels':         torch.tensor(label, dtype=torch.long)\n        }\n        return item\n\nclass BertClassifier(nn.Module):\n    def __init__(self, model_name, num_labels, freeze_bert=False):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(model_name)\n        if freeze_bert:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n        hidden_size = self.bert.config.hidden_size\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(hidden_size, num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        # Use [CLS] token representation\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        return self.classifier(x)\n\n# Data loading & preprocessing\n\ndef load_data(filepath):\n    # df = pd.read_csv(filepath)\n    df = pd.read_excel(filepath)\n    df = df.dropna(subset=['translation', 'label']).reset_index(drop=True)\n    texts = df['translation'].tolist()\n    raw_labels = df['label'].astype(str).str.strip().tolist()\n    unique_labels = sorted(set(raw_labels))\n    label_map = {lbl: i for i, lbl in enumerate(unique_labels)}\n    labels = [label_map[l] for l in raw_labels]\n    return texts, labels, label_map\n\n# Prepare datasets and loaders\ntexts, labels, label_map = load_data('/kaggle/input/phishing-email-vietnamese-v2-excel/phishing_email_with_translation_clean_small.xlsx')\ndataset = EmailDataset(texts, labels, tokenizer, MAX_LEN)\ntest_size = int(len(dataset) * TEST_SPLIT_RATIO)\ntrain_size= len(dataset) - test_size\ntrain_ds, test_ds = random_split(dataset, [train_size, test_size])\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE)\n\n# Initialize model, optimizer, scheduler, loss\nmodel = BertClassifier(MODEL_NAME, num_labels=len(label_map), freeze_bert=FREEZE_BERT).to(DEVICE)\noptimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\ntotal_steps = len(train_loader) * NUM_EPOCHS\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\ncriterion = nn.CrossEntropyLoss()\n\n# Training & evaluation loops\n\nbest_f1 = 0\nepochs_no_improve = 0\nfor epoch in range(NUM_EPOCHS):\n    # Train\n    model.train()\n    train_loss = 0\n    all_preds, all_labels = [], []\n    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n        input_ids = batch['input_ids'].to(DEVICE)\n        attention_mask = batch['attention_mask'].to(DEVICE)\n        labels = batch['labels'].to(DEVICE)\n        optimizer.zero_grad()\n        logits = model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        train_loss += loss.item()\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels.cpu().numpy())\n    avg_train_loss = train_loss / len(train_loader)\n    train_acc = accuracy_score(all_labels, all_preds)\n    train_f1  = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n    print(f\"Epoch {epoch+1}: train_loss={avg_train_loss:.4f}, acc={train_acc:.4f}, f1={train_f1:.4f}\")\n\n    # Evaluate\n    model.eval()\n    eval_loss = 0\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(DEVICE)\n            attention_mask = batch['attention_mask'].to(DEVICE)\n            labels = batch['labels'].to(DEVICE)\n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n            eval_loss += loss.item()\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n    avg_eval_loss = eval_loss / len(test_loader)\n    eval_acc = accuracy_score(all_labels, all_preds)\n    eval_f1  = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n    print(f\"Validation: loss={avg_eval_loss:.4f}, acc={eval_acc:.4f}, f1={eval_f1:.4f}\")\n\n    # Early stopping & save best\n    if eval_f1 > best_f1:\n        best_f1 = eval_f1\n        epochs_no_improve = 0\n        torch.save(model.state_dict(), os.path.join(ARTIFACTS_DIR, 'best_model.pt'))\n        print(\"Saved best model.\")\n    else:\n        epochs_no_improve += 1\n        if epochs_no_improve >= PATIENCE:\n            print(\"Early stopping...\")\n            break\n\n# Final classification report and confusion matrix\nprint(\"\\n--- Final Evaluation on Test Set ---\")\nprint(classification_report(all_labels, all_preds, target_names=label_map.keys(), digits=4))\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport gc\nimport json\nimport random\n\nimport modin.pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nfrom torch.optim import AdamW\n\nMODEL_NAME = 'FacebookAI/xlm-roberta-base'\nMAX_LEN = 256\nBATCH_SIZE = 32\nNUM_EPOCHS = 2\nLR = 2e-5\nWARMUP_STEPS = 0\nWEIGHT_DECAY = 0.01\nTEST_SPLIT_RATIO = 0.2\nPATIENCE = 3\nFREEZE_BERT = False\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nARTIFACTS_DIR = 'artifacts_xlm_roberta_bilingual'\nos.makedirs(ARTIFACTS_DIR, exist_ok=True)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\nclass EmailDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        item = {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n        return item\n\nimport torch.nn.functional as F\n\nclass BertCNNLSTMClassifier(nn.Module):\n    def __init__(\n        self,\n        model_name,\n        num_labels,\n        freeze_bert=False,\n        cnn_filters=128,\n        cnn_kernel_size=3,\n        lstm_hidden_dim=128,\n        lstm_layers=1,\n        bidirectional=True,\n        dropout=0.3\n    ):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(model_name)\n        if freeze_bert:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n\n        hidden_size = self.bert.config.hidden_size\n\n        self.conv = nn.Conv1d(\n            in_channels=hidden_size,\n            out_channels=cnn_filters,\n            kernel_size=cnn_kernel_size,\n            padding=cnn_kernel_size // 2\n        )\n\n        self.lstm = nn.LSTM(\n            input_size=cnn_filters,\n            hidden_size=lstm_hidden_dim,\n            num_layers=lstm_layers,\n            batch_first=True,\n            bidirectional=bidirectional\n        )\n\n        lstm_output_dim = lstm_hidden_dim * (2 if bidirectional else 1)\n\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(lstm_output_dim, num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            return_dict=True\n        )\n        seq_out = outputs.last_hidden_state\n\n        x = seq_out.permute(0, 2, 1)\n        x = F.relu(self.conv(x))\n        x = x.permute(0, 2, 1)\n\n        out, (h_n, _) = self.lstm(x)\n\n        if self.lstm.bidirectional:\n            h_forward = h_n[-2]\n            h_backward = h_n[-1]\n            h = torch.cat((h_forward, h_backward), dim=1)\n        else:\n            h = h_n[-1]\n\n        h = self.dropout(h)\n        logits = self.classifier(h)\n        return logits\n\ndef load_data(filepath):\n    df = pd.read_excel(filepath)\n    df = df.dropna(subset=['text_combined', 'label']).reset_index(drop=True)\n    texts = df['text_combined'].tolist()\n    raw_labels = df['label'].astype(str).str.strip().tolist()\n    unique_labels = sorted(set(raw_labels))\n    label_map = {lbl: i for i, lbl in enumerate(unique_labels)}\n    labels = [label_map[l] for l in raw_labels]\n    return texts, labels, label_map\n\ntexts, labels, label_map = load_data('/kaggle/input/phishing-email-multilingual-v3/phishing_email_bilingual_with_label.xlsx')\ndataset = EmailDataset(texts, labels, tokenizer, MAX_LEN)\ntest_size = int(len(dataset) * TEST_SPLIT_RATIO)\ntrain_size = len(dataset) - test_size\ntrain_ds, test_ds = random_split(dataset, [train_size, test_size])\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n\nmodel = BertCNNLSTMClassifier(\n    model_name=MODEL_NAME,\n    num_labels=len(label_map),\n    freeze_bert=FREEZE_BERT,\n    cnn_filters=128,\n    cnn_kernel_size=3,\n    lstm_hidden_dim=128,\n    lstm_layers=1,\n    bidirectional=True,\n    dropout=0.3\n).to(DEVICE)\noptimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\ntotal_steps = len(train_loader) * NUM_EPOCHS\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\ncriterion = nn.CrossEntropyLoss()\n\nbest_f1 = 0\nepochs_no_improve = 0\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    train_loss = 0\n    all_preds, all_labels = [], []\n    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n        input_ids = batch['input_ids'].to(DEVICE)\n        attention_mask = batch['attention_mask'].to(DEVICE)\n        labels = batch['labels'].to(DEVICE)\n        optimizer.zero_grad()\n        logits = model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        train_loss += loss.item()\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels.cpu().numpy())\n    avg_train_loss = train_loss / len(train_loader)\n    train_acc = accuracy_score(all_labels, all_preds)\n    train_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n    print(f\"Epoch {epoch+1}: train_loss={avg_train_loss:.4f}, acc={train_acc:.4f}, f1={train_f1:.4f}\")\n\n    model.eval()\n    eval_loss = 0\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(DEVICE)\n            attention_mask = batch['attention_mask'].to(DEVICE)\n            labels = batch['labels'].to(DEVICE)\n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n            eval_loss += loss.item()\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n    avg_eval_loss = eval_loss / len(test_loader)\n    eval_acc = accuracy_score(all_labels, all_preds)\n    eval_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n    print(f\"Validation: loss={avg_eval_loss:.4f}, acc={eval_acc:.4f}, f1={eval_f1:.4f}\")\n\n    if eval_f1 > best_f1:\n        best_f1 = eval_f1\n        epochs_no_improve = 0\n        torch.save(model.state_dict(), os.path.join(ARTIFACTS_DIR, 'best_model.pt'))\n        print(\"Saved best model.\")\n    else:\n        epochs_no_improve += 1\n        if epochs_no_improve >= PATIENCE:\n            print(\"Early stopping...\")\n            break\n\nloaded_model = BertCNNLSTMClassifier(\n    model_name=MODEL_NAME,\n    num_labels=len(label_map),\n    freeze_bert=FREEZE_BERT\n).to(DEVICE)\nloaded_model.load_state_dict(torch.load(os.path.join(ARTIFACTS_DIR, 'best_model.pt')))\nloaded_model.eval()\n\nprint(\"\\n--- Evaluation of Loaded Best Model on Test Set ---\")\nall_preds_loaded, all_labels_loaded = [], []\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Evaluating Loaded Model\"):\n        input_ids = batch['input_ids'].to(DEVICE)\n        attention_mask = batch['attention_mask'].to(DEVICE)\n        labels_batch = batch['labels'].to(DEVICE)\n        logits = loaded_model(input_ids, attention_mask)\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        all_preds_loaded.extend(preds)\n        all_labels_loaded.extend(labels_batch.cpu().numpy())\n\nprint(\"\\n--- Final Evaluation on Test Set ---\")\nprint(classification_report(all_labels, all_preds, target_names=label_map.keys(), digits=4))\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T10:40:18.212700Z","iopub.execute_input":"2025-05-07T10:40:18.212977Z"}},"outputs":[{"name":"stderr","text":"UserWarning: The size of /dev/shm is too small (14495514624 bytes). The required size at least half of RAM (16831176704 bytes). Please, delete files in /dev/shm or increase size of /dev/shm with --shm-size in Docker. Also, you can can override the memory size for each Ray worker (in bytes) to the MODIN_MEMORY environment variable.\n2025-05-07 10:40:25,942\tINFO worker.py:1852 -- Started a local Ray instance.\nUserWarning: Parallel `read_excel` is a new feature! If you run into any problems, please visit https://github.com/modin-project/modin/issues. If you find a new issue and can't file it on GitHub, please email bug_reports@modin.org.\nUserWarning: <function Series.tolist> is not currently supported by PandasOnRay, defaulting to pandas implementation.\nPlease refer to https://modin.readthedocs.io/en/stable/supported_apis/defaulting_to_pandas.html for explanation.\nUserWarning: <function Series.tolist> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n2025-05-07 10:40:43.637337: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746614443.660843     868 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746614443.667842     868 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training Epoch 1:   0%|          | 0/3488 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"260536c47adb4e549e5a136feac57230"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\n\nfolder_path = '/kaggle/working/artifacts'\nzip_name = 'email_cnn_bilstm_attention.zip'\n\nwith zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            # arcname makes the zip structure relative\n            arcname = os.path.relpath(file_path, start=folder_path)\n            zipf.write(file_path, arcname=arcname)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive('email_cnn_bilstm_attention_1', 'zip', '/kaggle/working/artifacts')\nfrom IPython.display import FileLink\nFileLink(r'email_cnn_bilstm_attention_1.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"123123123 123123 123123213 1123123","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf /kaggle/working/artifacts 123123123","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}